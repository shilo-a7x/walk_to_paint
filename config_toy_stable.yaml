dataset:
  data_dir: data/toy
  edge_list_file: out.toy
  edge_split_file: splits.json
  encoded_file: encoded.pt
  mask_ratio: 0.1
  max_walk_length: 3
  meta_file: meta.json
  name: toy
  num_walks: 1500
  tokenizer_file: tokenizer.json
  train_ratio: 0.7
  val_ratio: 0.1
  walks_file: walks.json
model:
  dropout: 0.1
  embedding_dim: 16
  hidden_dim: 32
  nhead: 2
  nlayers: 1
preprocess:
  save: true
  use_cache: true
training:
  batch_size: 2
  checkpoint_dir: checkpoints/
  early_stopping_patience: 10
  epochs: 3
  eval_only: false
  exp_name: walk_to_paint_toy_stable
  gradient_clip_val: 0.5  # Lower gradient clipping
  log_dir: logs/
  lr: 1e-4  # Much lower learning rate
  resume_from_checkpoint: null
  use_cuda: true
  weight_decay: 1e-3  # Higher weight decay for regularization
