dataset:
    data_dir: data/toy
    edge_list_file: out.toy
    edge_split_file: splits.json
    encoded_file: encoded.pt
    mask_ratio: 0.1
    max_walk_length: 3
    meta_file: meta.json
    name: toy
    num_walks: 1500
    tokenizer_file: tokenizer.json
    train_ratio: 0.7
    val_ratio: 0.1
    walks_file: walks.json
model:
    dropout: 0.1
    embedding_dim: 16
    hidden_dim: 32
    nhead: 2
    nlayers: 1
preprocess:
    save: true
    use_cache: true
training:
    batch_size: 2
    checkpoint_dir: checkpoints/
    early_stopping_patience: 10
    epochs: 10
    eval_only: false
    exp_name: walk_to_paint_experiment
    gradient_clip_val: 1.0
    log_dir: logs/
    lr: 1e-3
    resume_from_checkpoint: null
    use_cuda: true
    weight_decay: 1e-5
